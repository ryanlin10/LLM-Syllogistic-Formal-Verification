# Configuration file for SyLLM project

# Model Configuration
model:
  base_model: "deepseek-ai/deepseek-v3"  # Base model path
  max_length: 2048
  use_lora: true
  lora_rank: 16
  lora_alpha: 32
  lora_dropout: 0.1
  target_modules: ["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]

# Training Configuration
training:
  output_dir: "./models/finetuned"
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2e-4
  num_train_epochs: 3
  warmup_steps: 500
  logging_steps: 50
  save_steps: 1000
  evaluation_strategy: "steps"
  eval_steps: 500
  save_total_limit: 3
  fp16: true
  gradient_checkpointing: true
  report_to: "wandb"  # Set to "none" to disable

# RLHF Configuration
rlhf:
  output_dir: "./models/rlhf"
  learning_rate: 1e-6
  batch_size: 4
  mini_batch_size: 2
  gradient_accumulation_steps: 4
  ppo_epochs: 4
  cliprange: 0.2
  cliprange_value: 0.2
  gamma: 1.0
  lam: 0.95
  kl_penalty: "kl"  # "kl" or "full"
  kl_init: 0.0

# Data Configuration
data:
  train_path: "./data/train.jsonl"
  val_path: "./data/val.jsonl"
  test_path: "./data/test.jsonl"
  synthetic_data_path: "./data/synthetic.jsonl"
  max_samples: null  # null = use all
  seed: 42

# Retrieval Configuration
retrieval:
  index_path: "./data/retrieval_index"
  embedding_model: "sentence-transformers/all-mpnet-base-v2"
  top_k: 5
  chunk_size: 512
  chunk_overlap: 50

# Verifier Configuration
verifier:
  premise_model_path: "./models/verifier/premise"
  inference_model_path: "./models/verifier/inference"
  confidence_threshold: 0.85
  batch_size: 32

# Evaluation Configuration
evaluation:
  metrics: ["premise_precision", "premise_recall", "evidence_recall", "entailment_accuracy", "verifier_calibration"]
  human_eval_sample: 0.1  # Fraction of test set for human evaluation

# Output Schema
schema:
  required_fields: ["premises", "conclusion"]
  premises_min: 1
  premises_max: 10
  conclusion_max_length: 500

# System Prompt Template
prompts:
  system_prompt: |
    You must respond only in valid JSON format. Your response must contain exactly two fields:
    1. "premises": an array of concise factual statements (premises) that support your conclusion
    2. "conclusion": a single sentence that follows logically from the premises
    
    Each premise should be a factual statement that can be verified. Link premises to evidence when available.
    Ensure the conclusion follows logically from all the premises provided.
  
  user_template: |
    Question: {question}
    Context: {context}

# Paths
paths:
  data_dir: "./data"
  models_dir: "./models"
  logs_dir: "./logs"
  outputs_dir: "./outputs"

